{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import empty , cat , arange, Tensor\n",
    "from torch.nn.functional import fold, unfold\n",
    "import torch\n",
    "\n",
    "class Module(object):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def backward(self, *gradwrtoutput):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def param(self):\n",
    "        return []\n",
    "\n",
    "class Conv2d(Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.padding = padding\n",
    "\n",
    "        if (isinstance(kernel_size, int)):\n",
    "            self.kernel_size = (kernel_size, kernel_size)\n",
    "        elif (isinstance(kernel_size, tuple)):\n",
    "            self.kernel_size = kernel_size\n",
    "\n",
    "        if (isinstance(stride, int)):\n",
    "            self.stride = (stride, stride)\n",
    "        elif (isinstance(stride, tuple)):\n",
    "            self.stride = stride    \n",
    "\n",
    "        self.weight = empty((in_channels, out_channels, self.kernel_size[0], self.kernel_size[1]))\n",
    "        self.bias = empty(out_channels)\n",
    "\n",
    "        self.weightGrads = empty((in_channels, out_channels, self.kernel_size[0], self.kernel_size[1])).zero_()\n",
    "        self.biasGrads = empty(out_channels).zero_()\n",
    "        self.cache = {}\n",
    "\n",
    "    def _inputMat(self, input : Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        For input with the shape of (2, 2, h, w), \n",
    "        it will be flatten and transposed into a (2, h*w, 2) matrix:\n",
    "                \n",
    "              ic0   ic1\n",
    "\n",
    "        d0:  |h*w| |h*w|\n",
    "\n",
    "        d1:  |h*w| |h*w|\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        (bs, c, _, _) = input.shape\n",
    "        return input.reshape(bs, c, -1).transpose(1, 2) # (bs, ic, h, w) -> (bs, h*w, ic)\n",
    "\n",
    "    def _filterMat(self) -> Tensor:\n",
    "        \"\"\"\n",
    "        For weight with the shape of (2, 3, s0, s1), \n",
    "        it will be flatten into a (2, 3*s0*s1) matrix:\n",
    "             \n",
    "               oc0     oc1     oc2\n",
    "\n",
    "        ic0: |s0*s1| |s0*s1| |s0*s1|\n",
    "\n",
    "        ic1: |s0*s1| |s0*s1| |s0*s1|\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        return self.weight.reshape(self.in_channels, -1) # (ic, oc, s0, s1) -> (ic, oc*s0*s1)\n",
    "\n",
    "    def forward(self, input : Tensor):\n",
    "        bs, ic, H, W = input.size()\n",
    "        ic, oc, h, w = self.weight.size()\n",
    "        unfold_input = torch.nn.functional.unfold(input, self.kernel_size, self.stride)\n",
    "        weight = self.weight.view(oc, -1)\n",
    "        output = ((weight @ unfold_input) + self.bias.view(-1,1)).view(bs, oc, ((H-h+1)/self.stride[0]).floor(), -1)\n",
    "\n",
    "        self.cache[\"unfold_input\"] = unfold_input\n",
    "        self.cache[\"input\"] = input\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, gradwrtoutput: Tensor):\n",
    "        '''\n",
    "        gradwrtoutput shape (N, oc, Hout, Wout)\n",
    "        - Hout = 1 + (H + 2 * pad - h) / stride\n",
    "        - Wout = 1 + (W + 2 * pad - w) / stride\n",
    "        '''\n",
    "        input = self.cache[\"input\"]\n",
    "        gradient_reshape = gradwrtoutput.permute(1, 2, 3, 0).reshape(self.out_channels, -1)\n",
    "        unfold_input = self.cache[\"unfold_input\"].permute(2, 0, 1).reshape(gradient_reshape.shape[1], -1) \n",
    "\n",
    "        self.weightGrads += (gradient_reshape @ unfold_input).reshape(self.weight.shape)\n",
    "        self.biasGrads += gradwrtoutput.sum(dim=(0, 2, 3))\n",
    "\n",
    "        weight_reshaped = self.weight.reshape(self.out_channels, -1)\n",
    "        dx = weight_reshaped.t() @ gradient_reshape\n",
    "        dx = dx.reshape(self.cache[\"unfold_input\"].permute(1, 2, 0).shape).permute(2, 0, 1)\n",
    "        dx = dx.fold(dx, (input.shape[2],input.shape[3]), kernel_size=self.kernel_size, stride=self.stride)\n",
    "        return dx\n",
    "\n",
    "    def param(self):\n",
    "        return [(self.weight, self.weightGrads), (self.bias, self.biasGrads)]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
